{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "in iteration 0the accuracy is : 0.084\n",
      "in iteration 1the accuracy is : 0.1049\n",
      "in iteration 2the accuracy is : 0.1291\n",
      "in iteration 3the accuracy is : 0.1495\n",
      "in iteration 4the accuracy is : 0.1653\n",
      "in iteration 5the accuracy is : 0.1782\n",
      "in iteration 6the accuracy is : 0.19\n",
      "in iteration 7the accuracy is : 0.199\n",
      "in iteration 8the accuracy is : 0.208\n",
      "in iteration 9the accuracy is : 0.2164\n",
      "in iteration 10the accuracy is : 0.2268\n",
      "in iteration 11the accuracy is : 0.2378\n",
      "in iteration 12the accuracy is : 0.2573\n",
      "in iteration 13the accuracy is : 0.2789\n",
      "in iteration 14the accuracy is : 0.297\n",
      "in iteration 15the accuracy is : 0.3123\n",
      "in iteration 16the accuracy is : 0.3262\n",
      "in iteration 17the accuracy is : 0.3374\n",
      "in iteration 18the accuracy is : 0.3506\n",
      "in iteration 19the accuracy is : 0.3636\n",
      "in iteration 20the accuracy is : 0.3773\n",
      "in iteration 21the accuracy is : 0.3898\n",
      "in iteration 22the accuracy is : 0.4\n",
      "in iteration 23the accuracy is : 0.4119\n",
      "in iteration 24the accuracy is : 0.4246\n",
      "in iteration 25the accuracy is : 0.435\n",
      "in iteration 26the accuracy is : 0.4444\n",
      "in iteration 27the accuracy is : 0.4554\n",
      "in iteration 28the accuracy is : 0.4644\n",
      "in iteration 29the accuracy is : 0.4735\n",
      "in iteration 30the accuracy is : 0.4811\n",
      "in iteration 31the accuracy is : 0.4893\n",
      "in iteration 32the accuracy is : 0.4963\n",
      "in iteration 33the accuracy is : 0.5029\n",
      "in iteration 34the accuracy is : 0.5068\n",
      "in iteration 35the accuracy is : 0.5128\n",
      "in iteration 36the accuracy is : 0.5184\n",
      "in iteration 37the accuracy is : 0.5248\n",
      "in iteration 38the accuracy is : 0.5301\n",
      "in iteration 39the accuracy is : 0.5337\n",
      "in iteration 40the accuracy is : 0.5378\n",
      "in iteration 41the accuracy is : 0.5423\n",
      "in iteration 42the accuracy is : 0.5463\n",
      "in iteration 43the accuracy is : 0.5496\n",
      "in iteration 44the accuracy is : 0.5525\n",
      "in iteration 45the accuracy is : 0.5549\n",
      "in iteration 46the accuracy is : 0.5595\n",
      "in iteration 47the accuracy is : 0.5625\n",
      "in iteration 48the accuracy is : 0.565\n",
      "in iteration 49the accuracy is : 0.5683\n"
     ]
    }
   ],
   "source": [
    "# 数据集介绍\n",
    "# MNIST数据集，100k的训练数据，10k的预测数据，数据由tensorflow中的examples.tutorials.mnist读取 \n",
    "# 数据集介绍：：Yann LeCun's website\n",
    "# 由28*28的像素组成输入特征，输出特征为0-9的数字\n",
    "\n",
    "# 可调节参数：\n",
    "# --------\n",
    "# batch_size, initial_weight,二次损失函数,learning_rate,epoch_n\n",
    "# --------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True)\n",
    "\n",
    "# mini_batch的大小\n",
    "batch_size = 100\n",
    "batch_n = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 创建一个命名空间\n",
    "with tf.name_scope(\"input\"):\n",
    "    # # 定义两个placeholder用来feed数据，分别代表x和y --784列和10列(one-hot)\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name = \"x_input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name = \"y_input\")\n",
    "\n",
    "# # ----\n",
    "# # 构建多分类回归\n",
    "# # 定义weight和bias，初始化分别为正态随机和0.0\n",
    "with tf.name_scope(\"lager\"):\n",
    "    with tf.name_scope(\"weight\"):\n",
    "        initial_weight = tf.random_normal([784, 10])\n",
    "        weight = tf.Variable(initial_weight)\n",
    "    with tf.name_scope(\"bias\"):\n",
    "        bias = tf.Variable(tf.zeros([10]))\n",
    "    with tf.name_scope(\"mat_and_plus\"):\n",
    "        a = tf.matmul(x, weight) + bias\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        y_head = tf.nn.softmax(a)\n",
    "\n",
    "# # 定义二次损失函数并依据梯度下降法进行训练 -- 这样梯度下降的train就变成了x和y的函数\n",
    "with tf.name_scope(\"loss\"):\n",
    "    learning_rate = 0.1\n",
    "    loss = tf.reduce_mean(tf.square(y - y_head))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_head, 1)) # tf.argmax找到x中等于1的最大的id\n",
    "    correction = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # tf.cast 转换类型，将bool转为float，从而求得准确率\n",
    "\n",
    "# 迭代500次，进行mini_batch梯度下降\n",
    "epoch_n = 50\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    writer = tf.summary.FileWriter(logdir = \"d://tensorboardLogDir/logs/\", graph = session.graph) # 最好不要放到带中文字符的路径\n",
    "    for step in range(epoch_n):\n",
    "        for batch in range(batch_n):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            session.run(train, feed_dict= {x: batch_x, y: batch_y}) # 此处是最小化\n",
    "        corr = session.run(correction, feed_dict= {x: mnist.test.images, y: mnist.test.labels}) # 基于测试集对准确率进行测试\n",
    "        print(\"in iteration \" + str(step) + \"the accuracy is : \" + str(corr)) # 打印准确率\n",
    "# 这里看似有问题，其实没问题，因为图没变，DAG对输入的batch依次执行梯度下降法，\n",
    "# 并执行epoch_n个周期，权重会更新epoch_n * batch_n次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
